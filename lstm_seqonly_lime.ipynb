{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import h5py as h5f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "import six\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "#from dna import *\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop,Adam, SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import  Dropout, Activation, Flatten\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from keras.constraints import maxnorm\n",
    "#from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, LSTM, Bidirectional, BatchNormalization, MaxPooling2D, AveragePooling1D, Input, Multiply, Add, UpSampling1D,Concatenate\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import scipy.stats as st\n",
    "#from keras.utils import plot_model\n",
    "#from keras.utils.layer_utils import print_layer_shapes\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import shuffle\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(1369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PREPROCESS(lines):    \n",
    "    data_n = len(lines)\n",
    "    SEQ = np.zeros((data_n, 28, 4), dtype=int)\n",
    "    Score = np.zeros((data_n, 1), dtype=float)\n",
    "    for l in range(0, data_n):\n",
    "        seq = lines[l]\n",
    "        for i in range(28):\n",
    "            if seq[i] in \"Aa\":\n",
    "                SEQ[l, i, 0] = 1\n",
    "            elif seq[i] in \"Cc\":\n",
    "                SEQ[l, i, 1] = 1\n",
    "            elif seq[i] in \"Gg\":\n",
    "                SEQ[l, i, 2] = 1\n",
    "            elif seq[i] in \"Tt\":\n",
    "                SEQ[l, i, 3] = 1\n",
    "        #CA[l-1,0] = int(data[2])*100\n",
    "\t\n",
    "    return SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode \n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGC(seq):\n",
    "    '''\n",
    "    GC content for only the 20mer, as per the Doench paper/code\n",
    "    '''\n",
    "    return len( seq[3:23].replace( 'A', '' ).replace( 'T', '' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_cont(seq):\n",
    "    return (seq.count( 'G' ) + seq.count( 'C' )) / float( len( seq ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478786, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('kmarc_medium_cs.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Temperature'] = df.Temperature.astype('category')\n",
    "df['Medium'] = df.Medium.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Guide No.             float64\n",
       "location of crRNA      object\n",
       "20bp_crRNA             object\n",
       "28bp_crRNA             object\n",
       "Cutting_score         float64\n",
       "Temperature          category\n",
       "Medium               category\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['Temperature','Medium']\n",
    "df_enc = one_hot(df,col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = shuffle(df_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_seq = df_enc['28bp_crRNA'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = df_enc.loc[:,['Medium_glucose', 'Medium_lactose','Medium_xylose']]\n",
    "temp = df_enc.loc[:,['Temperature_30', 'Temperature_37']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_arr = med.values\n",
    "temp_arr = temp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478786, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_temp_arr = np.concatenate((med_arr,temp_arr), axis =1)\n",
    "med_temp_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_seq = df_enc['28bp_crRNA'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478786"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(guide_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = PREPROCESS(guide_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = df_enc.loc[:,'Cutting_score']\n",
    "score = score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = SEQ\n",
    "X_mt = med_temp_arr\n",
    "y = score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478786, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478786, 28, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(X_seq.shape[0] * 0.6)\n",
    "val_size = train_size +int(X_seq.shape[0] * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_f = X_seq.reshape(X_seq.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478786, 112)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478786, 1, 112)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_ff = np.expand_dims(X_seq_f, axis=1)\n",
    "X_seq_ff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478786, 1, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mt_f = np.expand_dims(X_mt, axis =1)\n",
    "X_mt_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.concatenate((X_seq_ff, X_mt_f), axis=2)\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_seq_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = []\n",
    "for pos in range(0,28):\n",
    "    pos_features.append(str(pos)+'_'+'a')\n",
    "    pos_features.append(str(pos)+'_'+'c')\n",
    "    pos_features.append(str(pos)+'_'+'g')\n",
    "    pos_features.append(str(pos)+'_'+'t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_featutes =['temp_0','temp_1','med_0','med_1','med_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mt_features = pos_features + mt_featutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_mt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mt_features[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:train_size]\n",
    "X_val = X[train_size:val_size]\n",
    "X_test = X[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[0:train_size]\n",
    "y_val = y[train_size:val_size]\n",
    "y_test = y[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 112)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1, 32)             16512     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1, 16)             2624      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                1360      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 25,417\n",
      "Trainable params: 25,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SEQ = Input(shape=(1,112))\n",
    "blstm_1 = Bidirectional(LSTM(units=16, dropout=0.0,recurrent_dropout=0.0, return_sequences=True))(SEQ)\n",
    "blstm_2 = Bidirectional(LSTM(units=8,dropout=0.0, return_sequences=True))(blstm_1)\n",
    "flatten = Flatten()(blstm_2)\n",
    "dropout_1 = Dropout(0.5)(flatten)\n",
    "dense_1 = Dense(80, activation='relu', kernel_initializer='glorot_uniform')(dropout_1)\n",
    "dropout_2 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(units=40,  activation=\"relu\",kernel_initializer='glorot_uniform')(dropout_2)\n",
    "dropout_3 = Dropout(0.3)(dense_2)\n",
    "dense_3 = Dense(units=40,  activation=\"relu\",kernel_initializer='glorot_uniform')(dropout_3)\n",
    "out = Dense(units=1,  activation=\"linear\")(dense_3)\n",
    "model = Model(inputs = SEQ, outputs= out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4484/4489 [============================>.] - ETA: 0s - loss: 5.7187\n",
      "Epoch 00001: val_loss improved from inf to 5.07185, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 25s 6ms/step - loss: 5.7183 - val_loss: 5.0719\n",
      "Epoch 2/50\n",
      "4488/4489 [============================>.] - ETA: 0s - loss: 4.9878\n",
      "Epoch 00002: val_loss improved from 5.07185 to 4.77263, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 4.9877 - val_loss: 4.7726\n",
      "Epoch 3/50\n",
      "4486/4489 [============================>.] - ETA: 0s - loss: 4.6854\n",
      "Epoch 00003: val_loss improved from 4.77263 to 4.62455, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 4.6854 - val_loss: 4.6245\n",
      "Epoch 4/50\n",
      "4483/4489 [============================>.] - ETA: 0s - loss: 4.4597\n",
      "Epoch 00004: val_loss improved from 4.62455 to 4.45252, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 4.4591 - val_loss: 4.4525\n",
      "Epoch 5/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 4.3002\n",
      "Epoch 00005: val_loss improved from 4.45252 to 4.33594, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 4.2987 - val_loss: 4.3359\n",
      "Epoch 6/50\n",
      "4487/4489 [============================>.] - ETA: 0s - loss: 4.1740\n",
      "Epoch 00006: val_loss improved from 4.33594 to 4.24870, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 4.1741 - val_loss: 4.2487\n",
      "Epoch 7/50\n",
      "4484/4489 [============================>.] - ETA: 0s - loss: 4.0687\n",
      "Epoch 00007: val_loss improved from 4.24870 to 4.19479, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 4.0678 - val_loss: 4.1948\n",
      "Epoch 8/50\n",
      "4483/4489 [============================>.] - ETA: 0s - loss: 3.9973\n",
      "Epoch 00008: val_loss improved from 4.19479 to 4.09879, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.9972 - val_loss: 4.0988\n",
      "Epoch 9/50\n",
      "4486/4489 [============================>.] - ETA: 0s - loss: 3.9206\n",
      "Epoch 00009: val_loss improved from 4.09879 to 4.08254, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.9204 - val_loss: 4.0825\n",
      "Epoch 10/50\n",
      "4479/4489 [============================>.] - ETA: 0s - loss: 3.8684\n",
      "Epoch 00010: val_loss improved from 4.08254 to 4.06445, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.8688 - val_loss: 4.0644\n",
      "Epoch 11/50\n",
      "4482/4489 [============================>.] - ETA: 0s - loss: 3.8229\n",
      "Epoch 00011: val_loss improved from 4.06445 to 4.02750, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.8221 - val_loss: 4.0275\n",
      "Epoch 12/50\n",
      "4479/4489 [============================>.] - ETA: 0s - loss: 3.7889\n",
      "Epoch 00012: val_loss improved from 4.02750 to 3.97016, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 27s 6ms/step - loss: 3.7890 - val_loss: 3.9702\n",
      "Epoch 13/50\n",
      "4484/4489 [============================>.] - ETA: 0s - loss: 3.7394\n",
      "Epoch 00013: val_loss improved from 3.97016 to 3.89135, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.7395 - val_loss: 3.8914\n",
      "Epoch 14/50\n",
      "4479/4489 [============================>.] - ETA: 0s - loss: 3.7072\n",
      "Epoch 00014: val_loss did not improve from 3.89135\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.7067 - val_loss: 3.9014\n",
      "Epoch 15/50\n",
      "4482/4489 [============================>.] - ETA: 0s - loss: 3.6725\n",
      "Epoch 00015: val_loss did not improve from 3.89135\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.6725 - val_loss: 3.9155\n",
      "Epoch 16/50\n",
      "4482/4489 [============================>.] - ETA: 0s - loss: 3.6469\n",
      "Epoch 00016: val_loss improved from 3.89135 to 3.85054, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 25s 6ms/step - loss: 3.6468 - val_loss: 3.8505\n",
      "Epoch 17/50\n",
      "4481/4489 [============================>.] - ETA: 0s - loss: 3.6098\n",
      "Epoch 00017: val_loss improved from 3.85054 to 3.84391, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.6095 - val_loss: 3.8439\n",
      "Epoch 18/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 3.5897\n",
      "Epoch 00018: val_loss improved from 3.84391 to 3.82457, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.5902 - val_loss: 3.8246\n",
      "Epoch 19/50\n",
      "4486/4489 [============================>.] - ETA: 0s - loss: 3.5724\n",
      "Epoch 00019: val_loss did not improve from 3.82457\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.5721 - val_loss: 3.8977\n",
      "Epoch 20/50\n",
      "4483/4489 [============================>.] - ETA: 0s - loss: 3.5366\n",
      "Epoch 00020: val_loss improved from 3.82457 to 3.76182, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.5369 - val_loss: 3.7618\n",
      "Epoch 21/50\n",
      "4487/4489 [============================>.] - ETA: 0s - loss: 3.5351\n",
      "Epoch 00021: val_loss improved from 3.76182 to 3.72312, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.5350 - val_loss: 3.7231\n",
      "Epoch 22/50\n",
      "4486/4489 [============================>.] - ETA: 0s - loss: 3.5089\n",
      "Epoch 00022: val_loss did not improve from 3.72312\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.5088 - val_loss: 3.8513\n",
      "Epoch 23/50\n",
      "4485/4489 [============================>.] - ETA: 0s - loss: 3.4976\n",
      "Epoch 00023: val_loss improved from 3.72312 to 3.70834, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.4977 - val_loss: 3.7083\n",
      "Epoch 24/50\n",
      "4481/4489 [============================>.] - ETA: 0s - loss: 3.4940\n",
      "Epoch 00024: val_loss did not improve from 3.70834\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.4939 - val_loss: 3.7730\n",
      "Epoch 25/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 3.4727\n",
      "Epoch 00025: val_loss did not improve from 3.70834\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.4729 - val_loss: 3.7338\n",
      "Epoch 26/50\n",
      "4482/4489 [============================>.] - ETA: 0s - loss: 3.4606\n",
      "Epoch 00026: val_loss did not improve from 3.70834\n",
      "4489/4489 [==============================] - 25s 6ms/step - loss: 3.4609 - val_loss: 3.7452\n",
      "Epoch 27/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 3.4385\n",
      "Epoch 00027: val_loss did not improve from 3.70834\n",
      "4489/4489 [==============================] - 25s 6ms/step - loss: 3.4379 - val_loss: 3.7830\n",
      "Epoch 28/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 3.4187\n",
      "Epoch 00028: val_loss improved from 3.70834 to 3.68673, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.4188 - val_loss: 3.6867\n",
      "Epoch 29/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 3.4061\n",
      "Epoch 00029: val_loss improved from 3.68673 to 3.64691, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.4061 - val_loss: 3.6469\n",
      "Epoch 30/50\n",
      "4489/4489 [==============================] - ETA: 0s - loss: 3.3867\n",
      "Epoch 00030: val_loss did not improve from 3.64691\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3867 - val_loss: 3.6801\n",
      "Epoch 31/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 3.3748\n",
      "Epoch 00031: val_loss did not improve from 3.64691\n",
      "4489/4489 [==============================] - 25s 5ms/step - loss: 3.3744 - val_loss: 3.6944\n",
      "Epoch 32/50\n",
      "4488/4489 [============================>.] - ETA: 0s - loss: 3.3683\n",
      "Epoch 00032: val_loss improved from 3.64691 to 3.60070, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3689 - val_loss: 3.6007\n",
      "Epoch 33/50\n",
      "4482/4489 [============================>.] - ETA: 0s - loss: 3.3522\n",
      "Epoch 00033: val_loss did not improve from 3.60070\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3528 - val_loss: 3.6646\n",
      "Epoch 34/50\n",
      "4485/4489 [============================>.] - ETA: 0s - loss: 3.3342\n",
      "Epoch 00034: val_loss improved from 3.60070 to 3.59197, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3344 - val_loss: 3.5920\n",
      "Epoch 35/50\n",
      "4481/4489 [============================>.] - ETA: 0s - loss: 3.3255\n",
      "Epoch 00035: val_loss improved from 3.59197 to 3.58642, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3276 - val_loss: 3.5864\n",
      "Epoch 36/50\n",
      "4488/4489 [============================>.] - ETA: 0s - loss: 3.3213\n",
      "Epoch 00036: val_loss did not improve from 3.58642\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3211 - val_loss: 3.6380\n",
      "Epoch 37/50\n",
      "4483/4489 [============================>.] - ETA: 0s - loss: 3.3165\n",
      "Epoch 00037: val_loss did not improve from 3.58642\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3165 - val_loss: 3.6889\n",
      "Epoch 38/50\n",
      "4488/4489 [============================>.] - ETA: 0s - loss: 3.3008\n",
      "Epoch 00038: val_loss improved from 3.58642 to 3.55554, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.3007 - val_loss: 3.5555\n",
      "Epoch 39/50\n",
      "4486/4489 [============================>.] - ETA: 0s - loss: 3.2890\n",
      "Epoch 00039: val_loss improved from 3.55554 to 3.52893, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2890 - val_loss: 3.5289\n",
      "Epoch 40/50\n",
      "4487/4489 [============================>.] - ETA: 0s - loss: 3.2884\n",
      "Epoch 00040: val_loss did not improve from 3.52893\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2880 - val_loss: 3.6275\n",
      "Epoch 41/50\n",
      "4489/4489 [==============================] - ETA: 0s - loss: 3.2763\n",
      "Epoch 00041: val_loss improved from 3.52893 to 3.51797, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 25s 5ms/step - loss: 3.2763 - val_loss: 3.5180\n",
      "Epoch 42/50\n",
      "4480/4489 [============================>.] - ETA: 0s - loss: 3.2722\n",
      "Epoch 00042: val_loss did not improve from 3.51797\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2725 - val_loss: 3.5849\n",
      "Epoch 43/50\n",
      "4482/4489 [============================>.] - ETA: 0s - loss: 3.2685\n",
      "Epoch 00043: val_loss did not improve from 3.51797\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2678 - val_loss: 3.5745\n",
      "Epoch 44/50\n",
      "4487/4489 [============================>.] - ETA: 0s - loss: 3.2586\n",
      "Epoch 00044: val_loss did not improve from 3.51797\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2585 - val_loss: 3.6037\n",
      "Epoch 45/50\n",
      "4485/4489 [============================>.] - ETA: 0s - loss: 3.2590\n",
      "Epoch 00045: val_loss did not improve from 3.51797\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2589 - val_loss: 3.6012\n",
      "Epoch 46/50\n",
      "4485/4489 [============================>.] - ETA: 0s - loss: 3.2510\n",
      "Epoch 00046: val_loss did not improve from 3.51797\n",
      "4489/4489 [==============================] - 25s 5ms/step - loss: 3.2511 - val_loss: 3.7026\n",
      "Epoch 47/50\n",
      "4482/4489 [============================>.] - ETA: 0s - loss: 3.2441\n",
      "Epoch 00047: val_loss did not improve from 3.51797\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2439 - val_loss: 3.5799\n",
      "Epoch 48/50\n",
      "4484/4489 [============================>.] - ETA: 0s - loss: 3.2419\n",
      "Epoch 00048: val_loss did not improve from 3.51797\n",
      "4489/4489 [==============================] - 24s 5ms/step - loss: 3.2416 - val_loss: 3.5882\n",
      "Epoch 49/50\n",
      "4488/4489 [============================>.] - ETA: 0s - loss: 3.2288\n",
      "Epoch 00049: val_loss improved from 3.51797 to 3.51740, saving model to seq_cs_lstm.hdf5\n",
      "4489/4489 [==============================] - 25s 6ms/step - loss: 3.2286 - val_loss: 3.5174\n",
      "Epoch 50/50\n",
      "4489/4489 [==============================] - ETA: 0s - loss: 3.2294\n",
      "Epoch 00050: val_loss did not improve from 3.51740\n",
      "4489/4489 [==============================] - 25s 6ms/step - loss: 3.2294 - val_loss: 3.5397\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "checkpointer = ModelCheckpoint(filepath=\"seq_cs_lstm.hdf5\",verbose=1, monitor='val_loss',save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "# add tensorboard\n",
    "tf_callbacks = tf.keras.callbacks.TensorBoard(log_dir = \"logs/fit\" , histogram_freq = 1)\n",
    "history = model.fit([X_train], y_train, batch_size=64, epochs=50, shuffle=True, validation_data=( [X_val], y_val), callbacks=[checkpointer,earlystopper,tf_callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.RecurrentTabularExplainer(X_train, training_labels=y_train, feature_names=pos_mt_features,\n",
    "                                                   discretize_continuous = False,\n",
    "                                                   mode = 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test[45], \n",
    "     model.predict, num_features=10)\n",
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.argsort(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[6897]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[95381]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[12300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[79840]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset\n",
      "mse 3.5700616156899785\n",
      "SpearmanrResult(correlation=0.7129045582101791, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.7262174091589781, pvalue=0.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('testset')\n",
    "pred_y = model.predict([X_test ])\n",
    "print('mse ' + str(mse(y_test, pred_y)))\n",
    "print(st.spearmanr(y_test, pred_y))\n",
    "y_pred_tr = model.predict([X_train])\n",
    "print(st.spearmanr(y_train, y_pred_tr)) \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7809944820519232, 0.0)\n"
     ]
    }
   ],
   "source": [
    "pred_y = pred_y.flatten()\n",
    "y_test = y_test.flatten()\n",
    "print(st.pearsonr(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test[12300], \n",
    "     model.predict, num_features=10)\n",
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test[52753], \n",
    "     model.predict, num_features=10)\n",
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 79840\n",
    "exp = explainer.explain_instance(X_test[ind], \n",
    "     model.predict, num_features=10)\n",
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 29400\n",
    "exp = explainer.explain_instance(X_test[ind], \n",
    "     model.predict, num_features=10)\n",
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 5832\n",
    "exp = explainer.explain_instance(X_test[ind], \n",
    "     model.predict, num_features=10)\n",
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
